{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96971742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import transformers\n",
    "import torch\n",
    "import circuitsvis as cv\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import einops\n",
    "from copy import deepcopy\n",
    "from fancy_einsum import einsum\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import HookedTransformer, FactoredMatrix, HookedTransformerConfig\n",
    "from jaxtyping import Float, Int\n",
    "from torch import Tensor\n",
    "import huggingface_hub\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from transformer_lens.ActivationCache import ActivationCache\n",
    "import re\n",
    "\n",
    "\n",
    "from utils.metrics import compare_token_probability, kl_divergence, compare_token_logit\n",
    "from utils.miscellanea import get_top_k_contributors, IOI_head_types\n",
    "from utils.component_contributions import contribution_mlp, contribution_attn\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "# torch.set_default_dtype(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40200857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.nodes import MLP_Node, EMBED_Node, FINAL_Node,Node, ATTN_Node\n",
    "from utils.graph_search import path_message, evaluate_path, breadth_first_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb53ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "TOKEN = os.getenv(\"TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9276fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "huggingface_hub.login(token=TOKEN)\n",
    "# model = HookedTransformer.from_pretrained('meta-llama/Llama-3.2-1B', device=DEVICE, torch_dtype=torch.bfloat16)\n",
    "model = HookedTransformer.from_pretrained('gpt2-small', device=DEVICE, torch_dtype=torch.bfloat16)\n",
    "find_subject_inibition = False\n",
    "if find_subject_inibition:\n",
    "    target_idx = 1\n",
    "else:\n",
    "    target_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = ['When John and Mary went to the shops, John gave the bag to', 'When John and Mary went to the shops, Mary gave the bag to', 'When Tom and James went to the park, Tom gave the ball to', 'When Tom and James went to the park, James gave the ball to', 'When Dan and Sid went to the shops, Dan gave an apple to', 'When Dan and Sid went to the shops, Sid gave an apple to', 'After Martin and Amy went to the park, Martin gave a drink to', 'After Martin and Amy went to the park, Amy gave a drink to']\n",
    "answers = [(' Mary', ' John'), (' John', ' Mary'), (' James', ' Tom'), (' Tom', ' James'), (' Sid', ' Dan'), (' Dan', ' Sid'), (' Amy', ' Martin'), (' Martin', ' Amy')]\n",
    "\n",
    "# Keep only the prompts where the second token is the indirect object\n",
    "prompts_fixed_pos = prompts[0::2]\n",
    "answers_fixed_pos = answers[0::2]\n",
    "\n",
    "example_idx = 2\n",
    "\n",
    "tokens = model.to_tokens(prompts[example_idx])\n",
    "logits, cache = model.run_with_cache(tokens)\n",
    "\n",
    "model_token = logits[0][-1].argmax(dim=-1)\n",
    "correct_tokens = model.to_tokens(str(answers[example_idx][0]))[:,-1]\n",
    "model_prediction = model.to_string(model_token)\n",
    "correct_prediction = str(answers[example_idx][0])\n",
    "n_layers = model.cfg.n_layers\n",
    "d_model = model.cfg.d_model\n",
    "n_heads = model.cfg.n_heads\n",
    "d_heads = model.cfg.d_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f814a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_metric = compare_token_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04162aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_treshold = 0.8 #0.25, #0.25, 2, 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3070589",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_paths, incomplete_paths = breadth_first_search(\n",
    "\tmodel,\n",
    "\tcache,\n",
    "\tdefault_metric,\n",
    "\tstart_node = [FINAL_Node(layer=model.cfg.n_layers-1, position=14)],\n",
    "\tground_truth_tokens = correct_tokens,\n",
    "\tmax_depth = 100, # max number of components in the path (max number of nodes -2)\n",
    "\tmax_branching_factor = 2048,\n",
    "\tmin_contribution = min_treshold,\n",
    "\tmin_contribution_percentage=0., #2, 5, 0.5\n",
    "\tinibition_task = find_subject_inibition\n",
    ")\n",
    "print(f\"Found {len(complete_paths)} complete paths and {len(incomplete_paths)} incomplete paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf5f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30190cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save circuit\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Convert the complete_paths to a serializable format\n",
    "def convert_path_to_dict(path_tuple):\n",
    "    score, path = path_tuple\n",
    "    path_dict = {\n",
    "        \"score\": float(score),\n",
    "        \"nodes\": []\n",
    "    }\n",
    "    \n",
    "    for node in path:\n",
    "        node_dict = {\n",
    "            \"type\": node.__class__.__name__,\n",
    "            \"layer\": node.layer,\n",
    "            \"position\": node.position\n",
    "        }\n",
    "        \n",
    "        # Add attention-specific attributes\n",
    "        if hasattr(node, 'head'):\n",
    "            node_dict[\"head\"] = node.head\n",
    "        if hasattr(node, 'keyvalue_position'):\n",
    "            node_dict[\"keyvalue_position\"] = node.keyvalue_position\n",
    "        if hasattr(node, 'patch_query'):\n",
    "            node_dict[\"patch_query\"] = node.patch_query\n",
    "        if hasattr(node, 'patch_keyvalue'):\n",
    "            node_dict[\"patch_keyvalue\"] = node.patch_keyvalue\n",
    "            \n",
    "        path_dict[\"nodes\"].append(node_dict)\n",
    "    \n",
    "    return path_dict\n",
    "\n",
    "# Convert all paths\n",
    "serializable_paths = [convert_path_to_dict(path) for path in complete_paths]\n",
    "\n",
    "# Create metadata\n",
    "metadata = {\n",
    "    \"model\": \"gpt2-small\",\n",
    "    \"prompt\": prompts[example_idx],\n",
    "    \"correct_answer\": str(answers[example_idx][0]),\n",
    "    \"target_idx\": target_idx,\n",
    "    \"find_subject_inhibition\": find_subject_inibition,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"total_paths\": len(complete_paths),\n",
    "    \"min_treshold\": min_treshold,\n",
    "    \"n_layers\": model.cfg.n_layers,\n",
    "    \"d_model\": model.cfg.d_model,\n",
    "    \"n_heads\": model.cfg.n_heads,\n",
    "    \"metric\": default_metric.__name__\n",
    "}\n",
    "\n",
    "# Combine data\n",
    "output_data = {\n",
    "    \"metadata\": metadata,\n",
    "    \"paths\": serializable_paths\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "filename = f\"detected_circuit_gpt2_ioi_{default_metric.__name__}_{min_treshold}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(output_data, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(complete_paths)} paths to {filename}\")\n",
    "print(f\"Top 3 paths by score:\")\n",
    "for i, path in enumerate(serializable_paths[:3]):\n",
    "    print(f\"  {i+1}. Score: {path['score']:.4f}, Nodes: {len(path['nodes'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b2c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
