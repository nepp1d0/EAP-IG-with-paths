{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96971742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import transformers\n",
    "import torch\n",
    "import circuitsvis as cv\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import einops\n",
    "from copy import deepcopy\n",
    "from fancy_einsum import einsum\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens import HookedTransformer, FactoredMatrix, HookedTransformerConfig\n",
    "from jaxtyping import Float, Int\n",
    "from torch import Tensor\n",
    "import huggingface_hub\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from transformer_lens.ActivationCache import ActivationCache\n",
    "import re\n",
    "\n",
    "\n",
    "from utils.metrics import compare_token_probability, kl_divergence, compare_token_logit\n",
    "from utils.miscellanea import get_top_k_contributors, IOI_head_types\n",
    "from utils.component_contributions import contribution_mlp, contribution_attn\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "# torch.set_default_dtype(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40200857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.nodes import MLP_Node, EMBED_Node, FINAL_Node,Node, ATTN_Node\n",
    "from utils.graph_search import path_message, evaluate_path, breadth_first_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb53ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "TOKEN = os.getenv(\"TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9276fc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "huggingface_hub.login(token=TOKEN)\n",
    "# Note: Eventually can set set fold_ln=False, center_unembed=False, center_writing_weights=False\n",
    "model = HookedTransformer.from_pretrained('gpt2-small', device=DEVICE, torch_dtype=torch.float32)\n",
    "find_subject_inibition = False\n",
    "if find_subject_inibition:\n",
    "    target_idx = 1\n",
    "else:\n",
    "    target_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c7c2c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = ['When John and Mary went to the shops, John gave the bag to', 'When John and Mary went to the shops, Mary gave the bag to', 'When Tom and James went to the park, Tom gave the ball to', 'When Tom and James went to the park, James gave the ball to', 'When Dan and Sid went to the shops, Dan gave an apple to', 'When Dan and Sid went to the shops, Sid gave an apple to', 'After Martin and Amy went to the park, Martin gave a drink to', 'After Martin and Amy went to the park, Amy gave a drink to']\n",
    "answers = [(' Mary', ' John'), (' John', ' Mary'), (' James', ' Tom'), (' Tom', ' James'), (' Sid', ' Dan'), (' Dan', ' Sid'), (' Amy', ' Martin'), (' Martin', ' Amy')]\n",
    "\n",
    "# Keep only the prompts where the second token is the indirect object\n",
    "# This is required because the search requires fixed input positions\n",
    "prompts_fixed_pos = prompts[0::2]\n",
    "answers_fixed_pos = answers[0::2]\n",
    "\n",
    "example_idx = 2\n",
    "\n",
    "tokens = model.to_tokens(prompts[example_idx])\n",
    "logits, cache = model.run_with_cache(prompts_fixed_pos)\n",
    "\n",
    "model_token = logits[0][-1].argmax(dim=-1)\n",
    "correct_tokens = [model.to_tokens(str(answers_fixed_pos[i][target_idx]))[0][-1].item() for i in range(len(prompts_fixed_pos))]\n",
    "n_layers = model.cfg.n_layers\n",
    "d_model = model.cfg.d_model\n",
    "n_heads = model.cfg.n_heads\n",
    "d_heads = model.cfg.d_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65f814a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_metric = compare_token_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04162aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_treshold = 0.8 #0.25, #0.25, 2, 0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3070589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BFS search:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring depth 1 with 1 paths in the frontier\n",
      "    Frontier: [(91.54667663574219, [FINAL_Node(layer=11, position=14)])](total 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BFS search:   1%|          | 1/100 [00:01<01:43,  1.05s/it, completed_paths=0, frontier_size=32]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring depth 2 with 32 paths in the frontier\n",
      "    Frontier: [(19.770381927490234, [ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (18.88329315185547, [ATTN_Node(layer=9, head=9, position=14, keyvalue_position=4, patch_query=False, patch_keyvalue=True), FINAL_Node(layer=11, position=14)]), (12.274027824401855, [ATTN_Node(layer=9, head=6, position=14, keyvalue_position=4, patch_query=False, patch_keyvalue=True), FINAL_Node(layer=11, position=14)]), (12.248641967773438, [ATTN_Node(layer=9, head=6, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)])]... ](total 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BFS search:   2%|▏         | 2/100 [00:11<10:29,  6.42s/it, completed_paths=0, frontier_size=139]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring depth 3 with 139 paths in the frontier\n",
      "    Frontier: [(10.142624855041504, [MLP_Node(layer=2, position=14), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (8.015645980834961, [ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (7.049868583679199, [ATTN_Node(layer=8, head=6, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (4.810174942016602, [MLP_Node(layer=0, position=14), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)])]... ](total 139)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BFS search:   3%|▎         | 3/100 [00:26<17:09, 10.62s/it, completed_paths=9, frontier_size=121]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring depth 4 with 121 paths in the frontier\n",
      "    Frontier: [(3.7176291942596436, [ATTN_Node(layer=5, head=5, position=10, keyvalue_position=None, patch_query=True, patch_keyvalue=False), ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (2.765381336212158, [ATTN_Node(layer=5, head=5, position=10, keyvalue_position=3, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (2.6335809230804443, [MLP_Node(layer=2, position=10), ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (1.8522632122039795, [ATTN_Node(layer=6, head=9, position=10, keyvalue_position=None, patch_query=True, patch_keyvalue=False), ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)])]... ](total 121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BFS search:   4%|▍         | 4/100 [00:38<17:24, 10.88s/it, completed_paths=10, frontier_size=48]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring depth 5 with 48 paths in the frontier\n",
      "    Frontier: [(4.174217224121094, [MLP_Node(layer=0, position=10), ATTN_Node(layer=5, head=5, position=10, keyvalue_position=None, patch_query=True, patch_keyvalue=False), ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (1.1933815479278564, [MLP_Node(layer=2, position=10), ATTN_Node(layer=5, head=5, position=10, keyvalue_position=None, patch_query=True, patch_keyvalue=False), ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (1.7553099393844604, [MLP_Node(layer=2, position=3), ATTN_Node(layer=5, head=5, position=10, keyvalue_position=3, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (0.8684837222099304, [ATTN_Node(layer=1, head=9, position=3, keyvalue_position=None, patch_query=True, patch_keyvalue=False), ATTN_Node(layer=5, head=5, position=10, keyvalue_position=3, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)])]... ](total 48)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BFS search:   5%|▌         | 5/100 [00:40<12:22,  7.82s/it, completed_paths=14, frontier_size=9] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring depth 6 with 9 paths in the frontier\n",
      "    Frontier: [(0.8668128252029419, [MLP_Node(layer=0, position=10), ATTN_Node(layer=3, head=0, position=10, keyvalue_position=None, patch_query=True, patch_keyvalue=False), ATTN_Node(layer=6, head=9, position=10, keyvalue_position=None, patch_query=True, patch_keyvalue=False), ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (0.8331685066223145, [MLP_Node(layer=0, position=3), ATTN_Node(layer=2, head=2, position=3, keyvalue_position=None, patch_query=True, patch_keyvalue=False), ATTN_Node(layer=6, head=9, position=10, keyvalue_position=3, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (0.8329135179519653, [ATTN_Node(layer=0, head=11, position=3, keyvalue_position=0, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=2, head=2, position=3, keyvalue_position=None, patch_query=True, patch_keyvalue=False), ATTN_Node(layer=6, head=9, position=10, keyvalue_position=3, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)]), (0.8327858448028564, [ATTN_Node(layer=0, head=11, position=3, keyvalue_position=1, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=2, head=2, position=3, keyvalue_position=None, patch_query=True, patch_keyvalue=False), ATTN_Node(layer=6, head=9, position=10, keyvalue_position=3, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True), ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False), FINAL_Node(layer=11, position=14)])]... ](total 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BFS search:   6%|▌         | 6/100 [00:40<10:38,  6.80s/it, completed_paths=14, frontier_size=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 complete paths and 0 incomplete paths.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "complete_paths, incomplete_paths = breadth_first_search(\n",
    "\tmodel,\n",
    "\tcache,\n",
    "\tdefault_metric,\n",
    "\tstart_node = [FINAL_Node(layer=model.cfg.n_layers-1, position=14)],\n",
    "\tground_truth_tokens = correct_tokens,\n",
    "\tmax_depth = 100, # max number of components in the path (max number of nodes -2)\n",
    "\tmax_branching_factor = 2048,\n",
    "\tmin_contribution = min_treshold,\n",
    "\tmin_contribution_percentage=0., #2, 5, 0.5\n",
    "\tinibition_task = find_subject_inibition\n",
    ")\n",
    "print(f\"Found {len(complete_paths)} complete paths and {len(incomplete_paths)} incomplete paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebcf5f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9.29843807220459,\n",
       "  [EMBED_Node(layer=0, position=4),\n",
       "   MLP_Node(layer=0, position=4),\n",
       "   ATTN_Node(layer=9, head=9, position=14, keyvalue_position=4, patch_query=False, patch_keyvalue=True),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (6.137215614318848,\n",
       "  [EMBED_Node(layer=0, position=4),\n",
       "   MLP_Node(layer=0, position=4),\n",
       "   ATTN_Node(layer=9, head=6, position=14, keyvalue_position=4, patch_query=False, patch_keyvalue=True),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (3.9328300952911377,\n",
       "  [EMBED_Node(layer=0, position=4),\n",
       "   MLP_Node(layer=0, position=4),\n",
       "   ATTN_Node(layer=10, head=0, position=14, keyvalue_position=4, patch_query=False, patch_keyvalue=True),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (1.5881882905960083,\n",
       "  [EMBED_Node(layer=0, position=10),\n",
       "   MLP_Node(layer=0, position=10),\n",
       "   ATTN_Node(layer=5, head=5, position=10, keyvalue_position=None, patch_query=True, patch_keyvalue=False),\n",
       "   ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True),\n",
       "   ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (1.5297662019729614,\n",
       "  [EMBED_Node(layer=0, position=4),\n",
       "   MLP_Node(layer=0, position=4),\n",
       "   ATTN_Node(layer=10, head=10, position=14, keyvalue_position=4, patch_query=False, patch_keyvalue=True),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (1.5017578601837158,\n",
       "  [EMBED_Node(layer=0, position=10),\n",
       "   MLP_Node(layer=0, position=10),\n",
       "   ATTN_Node(layer=6, head=9, position=10, keyvalue_position=None, patch_query=True, patch_keyvalue=False),\n",
       "   ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True),\n",
       "   ATTN_Node(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (1.4039742946624756,\n",
       "  [EMBED_Node(layer=0, position=14),\n",
       "   MLP_Node(layer=0, position=14),\n",
       "   MLP_Node(layer=8, position=14),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (1.355581521987915,\n",
       "  [EMBED_Node(layer=0, position=4),\n",
       "   ATTN_Node(layer=0, head=1, position=4, keyvalue_position=4, patch_query=False, patch_keyvalue=True),\n",
       "   ATTN_Node(layer=9, head=9, position=14, keyvalue_position=4, patch_query=False, patch_keyvalue=True),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (1.320690631866455,\n",
       "  [EMBED_Node(layer=0, position=4),\n",
       "   MLP_Node(layer=0, position=4),\n",
       "   ATTN_Node(layer=10, head=1, position=14, keyvalue_position=4, patch_query=False, patch_keyvalue=True),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (1.0581386089324951,\n",
       "  [EMBED_Node(layer=0, position=10),\n",
       "   MLP_Node(layer=0, position=10),\n",
       "   ATTN_Node(layer=5, head=5, position=10, keyvalue_position=None, patch_query=True, patch_keyvalue=False),\n",
       "   ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True),\n",
       "   ATTN_Node(layer=9, head=6, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (1.0455069541931152,\n",
       "  [EMBED_Node(layer=0, position=10),\n",
       "   MLP_Node(layer=0, position=10),\n",
       "   ATTN_Node(layer=6, head=9, position=10, keyvalue_position=None, patch_query=True, patch_keyvalue=False),\n",
       "   ATTN_Node(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_keyvalue=True),\n",
       "   ATTN_Node(layer=9, head=6, position=14, keyvalue_position=None, patch_query=True, patch_keyvalue=False),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (0.9876349568367004,\n",
       "  [EMBED_Node(layer=0, position=14),\n",
       "   MLP_Node(layer=0, position=14),\n",
       "   MLP_Node(layer=7, position=14),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (0.8991678953170776,\n",
       "  [EMBED_Node(layer=0, position=4),\n",
       "   ATTN_Node(layer=0, head=4, position=4, keyvalue_position=4, patch_query=False, patch_keyvalue=True),\n",
       "   ATTN_Node(layer=9, head=6, position=14, keyvalue_position=4, patch_query=False, patch_keyvalue=True),\n",
       "   FINAL_Node(layer=11, position=14)]),\n",
       " (0.8219773173332214,\n",
       "  [EMBED_Node(layer=0, position=4),\n",
       "   ATTN_Node(layer=0, head=1, position=4, keyvalue_position=None, patch_query=True, patch_keyvalue=False),\n",
       "   MLP_Node(layer=0, position=4),\n",
       "   ATTN_Node(layer=10, head=10, position=14, keyvalue_position=4, patch_query=False, patch_keyvalue=True),\n",
       "   FINAL_Node(layer=11, position=14)])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30190cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save circuit\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Convert the complete_paths to a serializable format\n",
    "def convert_path_to_dict(path_tuple):\n",
    "    score, path = path_tuple\n",
    "    path_dict = {\n",
    "        \"score\": float(score),\n",
    "        \"nodes\": []\n",
    "    }\n",
    "    \n",
    "    for node in path:\n",
    "        node_dict = {\n",
    "            \"type\": node.__class__.__name__,\n",
    "            \"layer\": node.layer,\n",
    "            \"position\": node.position\n",
    "        }\n",
    "        \n",
    "        # Add attention-specific attributes\n",
    "        if hasattr(node, 'head'):\n",
    "            node_dict[\"head\"] = node.head\n",
    "        if hasattr(node, 'keyvalue_position'):\n",
    "            node_dict[\"keyvalue_position\"] = node.keyvalue_position\n",
    "        if hasattr(node, 'patch_query'):\n",
    "            node_dict[\"patch_query\"] = node.patch_query\n",
    "        if hasattr(node, 'patch_keyvalue'):\n",
    "            node_dict[\"patch_keyvalue\"] = node.patch_keyvalue\n",
    "            \n",
    "        path_dict[\"nodes\"].append(node_dict)\n",
    "    \n",
    "    return path_dict\n",
    "\n",
    "# Convert all paths\n",
    "serializable_paths = [convert_path_to_dict(path) for path in complete_paths]\n",
    "\n",
    "# Create metadata\n",
    "metadata = {\n",
    "    \"model\": \"gpt2-small\",\n",
    "    \"prompt\": prompts[example_idx],\n",
    "    \"correct_answer\": str(answers[example_idx][0]),\n",
    "    \"target_idx\": target_idx,\n",
    "    \"find_subject_inhibition\": find_subject_inibition,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"total_paths\": len(complete_paths),\n",
    "    \"min_treshold\": min_treshold,\n",
    "    \"n_layers\": model.cfg.n_layers,\n",
    "    \"d_model\": model.cfg.d_model,\n",
    "    \"n_heads\": model.cfg.n_heads,\n",
    "    \"metric\": default_metric.__name__\n",
    "}\n",
    "\n",
    "# Combine data\n",
    "output_data = {\n",
    "    \"metadata\": metadata,\n",
    "    \"paths\": serializable_paths\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "filename = f\"detected_circuit_gpt2_ioi_{default_metric.__name__}_{min_treshold}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(output_data, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(complete_paths)} paths to {filename}\")\n",
    "print(f\"Top 3 paths by score:\")\n",
    "for i, path in enumerate(serializable_paths[:3]):\n",
    "    print(f\"  {i+1}. Score: {path['score']:.4f}, Nodes: {len(path['nodes'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b2c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (circuit-discovery)",
   "language": "python",
   "name": "circuit-discovery"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
