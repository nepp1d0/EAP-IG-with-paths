{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd4c9df",
   "metadata": {},
   "source": [
    "# Qwen 2.5 graph search for MIB submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e508c2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96971742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformer_lens import HookedTransformer\n",
    "import huggingface_hub\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils.metrics import compare_token_probability, kl_divergence, compare_token_logit\n",
    "from utils.nodes import MLP_Node, EMBED_Node, FINAL_Node, Node, ATTN_Node\n",
    "from utils.graph_search import path_message, evaluate_path, breadth_first_search, breadth_first_search_cached\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "# torch.set_default_dtype(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646607c1",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdb53ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "TOKEN = os.getenv(\"TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9276fc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model Qwen/Qwen2.5-0.5B into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "huggingface_hub.login(token=TOKEN)\n",
    "# Note: Eventually can set set fold_ln=False, center_unembed=False, center_writing_weights=False\n",
    "model = HookedTransformer.from_pretrained('Qwen/Qwen2.5-0.5B', \n",
    "                                          device=DEVICE, \n",
    "                                          torch_dtype=torch.float32, \n",
    "                                          center_unembed=True,\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ad626",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb2694f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"mcqa\" # \"ioi\" or \"mcqa\"\n",
    "TARGET_LENGTH = 32 # from 15 to 19 for ioi - from 32 to 37 for mcqa\n",
    "BATCH_SIZE = 16 # Number of samples from the dataset to consider\n",
    "DEFAULT_METRIC = compare_token_logit\n",
    "CONTRIBUTION_THRESHOLD = 1 # 0.25 -> 2700~ path for depth=10 with ioi / \n",
    "NOSPACE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ff1734b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16 samples for the task mcqa with target length 32.\n",
      "Sample prompt: \n",
      "''Question: Tin cans are gray. What color are tin cans?\n",
      "A. pink\n",
      "B. red\n",
      "C. yellow\n",
      "D. gray\n",
      "Answer:''\n",
      "Sample answer: ''D''\n",
      "Probability of the answer: 4.868205724051222e-05 ~ Logit: 14.339275360107422\n"
     ]
    }
   ],
   "source": [
    "samples = []\n",
    "samples_prompt = []\n",
    "sample_answers = []\n",
    "\n",
    "if TASK == \"ioi\":\n",
    "\ttrain_dataset = load_dataset('mib-bench/ioi', split='train')\n",
    "\tvalidation_dataset = load_dataset('mib-bench/ioi', split='validation')\n",
    "\ttest_dataset = load_dataset('mib-bench/ioi', split='test')\n",
    "\tfor sample in train_dataset:\n",
    "\t\tif model.to_tokens(sample['prompt'], prepend_bos=True).shape[1] == TARGET_LENGTH:\n",
    "\t\t\tsamples.append(sample)\n",
    "\t\t\tsamples_prompt.append(sample['prompt'])\n",
    "\t\t\tif NOSPACE:\n",
    "\t\t\t\tsample_answers.append(model.to_tokens(f'{sample[\"metadata\"][\"indirect_object\"]}', prepend_bos=False).item())\n",
    "\t\t\telse:\n",
    "\t\t\t\tsample_answers.append(model.to_tokens(f' {sample['metadata']['indirect_object']}', prepend_bos=False).item())\n",
    "\t\t\tif len(samples) >= BATCH_SIZE:\n",
    "\t\t\t\tbreak\n",
    "elif TASK == \"mcqa\":\n",
    "\ttrain_dataset = load_dataset('mib-bench/copycolors_mcqa', '4_answer_choices', split='train')\n",
    "\tvalidation_dataset = load_dataset('mib-bench/copycolors_mcqa', '4_answer_choices', split='validation')\n",
    "\ttest_dataset = load_dataset('mib-bench/copycolors_mcqa', '4_answer_choices', split='test')\n",
    "\tfor sample in train_dataset:\n",
    "\t\tif model.to_tokens(sample['prompt'], prepend_bos=True).shape[1] == TARGET_LENGTH:\n",
    "\t\t\tsamples.append(sample)\n",
    "\t\t\tsamples_prompt.append(sample['prompt'])\n",
    "\t\t\tif NOSPACE:\n",
    "\t\t\t\tsample_answers.append(model.to_tokens(f'{sample['choices']['label'][sample['answerKey']]}', prepend_bos=False).item())\n",
    "\t\t\telse:\n",
    "\t\t\t\tsample_answers.append(model.to_tokens(f' {sample['choices']['label'][sample['answerKey']]}', prepend_bos=False).item())\n",
    "\t\t\tif len(samples) >= BATCH_SIZE:\n",
    "\t\t\t\tbreak\n",
    "else:\n",
    "\traise ValueError(\"Unsupported task. Please choose 'ioi' or 'MCQA'.\")\n",
    "print(f\"Loaded {len(samples)} samples for the task {TASK} with target length {TARGET_LENGTH}.\")\n",
    "print(f\"Sample prompt: \\n''{samples_prompt[0]}''\")\n",
    "print(f\"Sample answer: ''{model.to_string(sample_answers[0])}''\")\n",
    "print(f\"Probability of the answer: {torch.softmax(model(samples_prompt[0], prepend_bos=True, return_type='logits')[0, -1], dim=-1)[sample_answers[0]].item()} ~ Logit: {model(samples_prompt[0], prepend_bos=True, return_type='logits')[0, -1, sample_answers[0]].item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b352f8",
   "metadata": {},
   "source": [
    "### Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09f765fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, cache = model.run_with_cache(samples_prompt, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f87f2",
   "metadata": {},
   "source": [
    "## Run the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3070589",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "complete_paths, incomplete_paths = breadth_first_search(\n",
    "\tmodel,\n",
    "\tcache,\n",
    "\tcompare_token_logit,\n",
    "\tstart_node = [FINAL_Node(layer=model.cfg.n_layers-1, position=TARGET_LENGTH-1)],\n",
    "\tground_truth_tokens = sample_answers,\n",
    "\tmax_depth = 10,\n",
    "\tmax_branching_factor = 2048,\n",
    "\tmin_contribution = CONTRIBUTION_THRESHOLD,\n",
    "\tmin_contribution_percentage=0.,\n",
    "\tinibition_task = False\n",
    ")\n",
    "print(f\"Found {len(complete_paths)} complete paths and {len(incomplete_paths)} incomplete paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d67bcefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded existing paths.\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "a = input(\"Load or save paths? (l/s): \").strip().lower()\n",
    "if a == 'l':\n",
    "\tload = True\n",
    "\tsave = False\n",
    "elif a == 's':\n",
    "\tload = False\n",
    "\tsave = True\n",
    "else:\n",
    "\tprint(\"Invalid input. Please enter 'l' to load or 's' to save.\")\n",
    "\tload = False\n",
    "\tsave = False\n",
    "if save:\n",
    "\twith open(f'paths_logit_th{CONTRIBUTION_THRESHOLD}_qwen.pkl', 'wb') as f:\n",
    "\t\t# if the file already exists, avoid overwriting it\n",
    "\t\tif os.path.exists(f.name):\n",
    "\t\t\tprint(f\"File {f.name} already exists.\")\n",
    "\t\t\tif input(\"Do you want to overwrite it? (y/n): \").strip().lower() == 'y':\n",
    "\t\t\t\tpkl.dump((complete_paths, incomplete_paths), f)\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint(\"File not overwritten.\")\n",
    "\t\telse:\n",
    "\t\t\tpkl.dump((complete_paths, incomplete_paths), f)\n",
    "\t\t\tprint(f\"Saved paths to {f.name}.\")\n",
    "\n",
    "if load:\n",
    "\twith open(f'paths_logit_th{0.5}_qwen_no_space.pkl', 'rb') as f:\n",
    "\t\tcomplete_paths, incomplete_paths = pkl.load(f)\n",
    "\t\tprint(\"Loaded existing paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30190cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 6418 paths to detected_paths/detected_circuit_qwen2.5_ioi_compare_token_logit_0.5_bs16_l15_nospace_and_space_20250725_135225.json\n",
      "Top 3 paths by score:\n",
      "  1. Score: 5.9555, Nodes: 7\n",
      "  2. Score: 5.5193, Nodes: 4\n",
      "  3. Score: 5.3024, Nodes: 4\n"
     ]
    }
   ],
   "source": [
    "# save circuit\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Convert the complete_paths to a serializable format\n",
    "def convert_path_to_dict(path_tuple):\n",
    "    score, path = path_tuple\n",
    "    path_dict = {\n",
    "        \"score\": float(score),\n",
    "        \"nodes\": []\n",
    "    }\n",
    "    \n",
    "    for node in path:\n",
    "        node_dict = {\n",
    "            \"type\": node.__class__.__name__,\n",
    "            \"layer\": node.layer,\n",
    "            \"position\": node.position\n",
    "        }\n",
    "        \n",
    "        # Add attention-specific attributes\n",
    "        if hasattr(node, 'head'):\n",
    "            node_dict[\"head\"] = node.head\n",
    "        if hasattr(node, 'keyvalue_position'):\n",
    "            node_dict[\"keyvalue_position\"] = node.keyvalue_position\n",
    "        if hasattr(node, 'patch_query'):\n",
    "            node_dict[\"patch_query\"] = node.patch_query\n",
    "        if hasattr(node, 'patch_keyvalue'):\n",
    "            node_dict[\"patch_keyvalue\"] = node.patch_keyvalue\n",
    "            \n",
    "        path_dict[\"nodes\"].append(node_dict)\n",
    "    \n",
    "    return path_dict\n",
    "\n",
    "# Convert all paths\n",
    "serializable_paths = [convert_path_to_dict(path) for path in complete_paths]\n",
    "serializable_paths = serializable_paths + [convert_path_to_dict(path) for path in incomplete_paths]\n",
    "# Create metadata\n",
    "metadata = {\n",
    "    \"model\": \"Qwen/Qwen2.5-0.5B\",\n",
    "    \"prompt\": samples_prompt[0],\n",
    "    \"correct_answer\": str(model.to_string(sample_answers[0])),\n",
    "    \"target_idx\": sample_answers[0],\n",
    "    \"find_subject_inhibition\": False,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"total_paths\": len(complete_paths + incomplete_paths),\n",
    "    \"min_treshold\": CONTRIBUTION_THRESHOLD,\n",
    "    \"n_layers\": model.cfg.n_layers,\n",
    "    \"d_model\": model.cfg.d_model,\n",
    "    \"n_heads\": model.cfg.n_heads,\n",
    "    \"metric\": DEFAULT_METRIC.__name__\n",
    "}\n",
    "\n",
    "# Combine data\n",
    "output_data = {\n",
    "    \"metadata\": metadata,\n",
    "    \"paths\": serializable_paths\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "if NOSPACE:\n",
    "\tfilename = f\"detected_paths/detected_circuit_qwen2.5_{TASK}_{DEFAULT_METRIC.__name__}_{CONTRIBUTION_THRESHOLD}_bs{BATCH_SIZE}_l{TARGET_LENGTH}_nospace_and_space_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "else:\n",
    "\tfilename = f\"detected_paths/detected_circuit_qwen2.5_{TASK}_{DEFAULT_METRIC.__name__}_{CONTRIBUTION_THRESHOLD}_bs{BATCH_SIZE}_l{TARGET_LENGTH}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(output_data, f, indent=2)\n",
    "\n",
    "print(f\"Saved {len(complete_paths + incomplete_paths)} paths to {filename}\")\n",
    "print(f\"Top 3 paths by score:\")\n",
    "for i, path in enumerate(serializable_paths[:3]):\n",
    "    print(f\"  {i+1}. Score: {path['score']:.4f}, Nodes: {len(path['nodes'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "circuit-discovery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
